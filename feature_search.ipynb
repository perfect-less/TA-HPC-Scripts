{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# TENSORFLOW LOGS:\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.api import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from hpcscripts.sharedutils.trainingutils import LoadModel, SetLowTFVerbose, MakeSinglePrediction, CreateWindowGenerator, GetFileList, TrainModel\n",
    "from hpcscripts.sharedutils.nomalization import DF_Nomalize, denorm\n",
    "from hpcscripts.sharedutils.modelutils import SelectModelPrompt\n",
    "from hpcscripts.trainers.anntrainer import CreateANNModel, ImportCombinedTrainingData\n",
    "from hpcscripts.trainers.modeldefinitions import  MODEL_DEFINITIONS\n",
    "from hpcscripts.trainers import modeldefinitions as mdef\n",
    "from hpcscripts.trainers import anntrainer\n",
    "from hpcscripts.option import pathhandler as ph\n",
    "from hpcscripts.option import globalparams as G_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Functions Defninition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary(digits_num: int, init_val: int=0):\n",
    "    return [init_val for i in range (digits_num)]\n",
    "\n",
    "def increment_binary(binary: list):\n",
    "    hold = 0\n",
    "    for i in range (len(binary)):\n",
    "        index = len(binary) - i - 1\n",
    "        \n",
    "        if index == 0 and binary[index] == 1 and hold > 0:\n",
    "            return -1\n",
    "        if i == 0:\n",
    "            binary [index] += 1\n",
    "\n",
    "        binary [index] += hold\n",
    "        hold = 0\n",
    "\n",
    "        if binary[index] > 1:\n",
    "            binary[index] = 0\n",
    "            hold = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def create_possibility_mask(digits_num: int):\n",
    "    possibilities = []\n",
    "    binary = create_binary(digits_num)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        binary = increment_binary(binary)\n",
    "\n",
    "        if binary == -1:\n",
    "            break\n",
    "\n",
    "        possibilities.append(binary.copy())\n",
    "\n",
    "    return possibilities\n",
    "\n",
    "def create_possible_features(feature_list: list):\n",
    "    digits_num = len (feature_list)\n",
    "    possi_mask = create_possibility_mask(digits_num)\n",
    "\n",
    "    feature_possibs = []\n",
    "    for possi in possi_mask:\n",
    "        new_features = []\n",
    "        for mask, feature in zip(possi, feature_list):\n",
    "            if mask == 1:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        feature_possibs.append(new_features)\n",
    "    \n",
    "    return feature_possibs, possi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(the_list: list):\n",
    "    for element in the_list:\n",
    "        print (element)\n",
    "        \n",
    "def bin_to_index(binary: str = \"1010\"):\n",
    "    index = -1\n",
    "    for n, letter in enumerate(binary[::-1]):\n",
    "        if letter == \"1\":\n",
    "            index += 2**n\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create Possible Labels Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of possibilities: 6\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad', 'tailwind_mps']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'tailwind_mps']\n"
     ]
    }
   ],
   "source": [
    "feature_list = [\n",
    "                'hralt_m', 'theta_rad', 'aoac_rad', 'cas_mps', 'hdot_1_mps',\n",
    "                'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad',\n",
    "                'tailwind_mps', 'crosswind_mps',\n",
    "                'use_flap'\n",
    "                ]\n",
    "                # 'flap_4_bool', 'flap_5_bool', 'flap_6_bool'\n",
    "# label_list = [\"hralt_m\", \"theta_rad\", \"aoac_rad\", \"cas_mps\"]\n",
    "# feature_list = [\"hralt_m\", \"theta_rad\"]\n",
    "\n",
    "feature_possibs, possi_mask = create_possible_features(feature_list)\n",
    "\n",
    "for i, feature_poss in enumerate (feature_possibs):\n",
    "    if 'use_flap' in feature_poss:\n",
    "        feature_poss.remove('use_flap')\n",
    "        feature_poss = feature_poss + ['flap_4_bool', 'flap_5_bool', 'flap_6_bool']\n",
    "\n",
    "        feature_possibs[i] = feature_poss\n",
    "\n",
    "\n",
    "# For Elevator\n",
    "feature_possibs = [ \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', ], \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad'], \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad'], \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad'], \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad', 'tailwind_mps'], \n",
    "                        ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'tailwind_mps'], \n",
    "                        #['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'tailwind_mps', 'flap_4_bool', 'flap_5_bool', 'flap_6_bool']\n",
    "                    ]\n",
    "\n",
    "# For Aileron\n",
    "feature_possibs = [ \n",
    "                        ['phi_rad',], \n",
    "                        ['phi_rad', 'loc_dev_ddm',], \n",
    "                        ['phi_rad', 'loc_dev_ddm', 'crosswind_mps',], \n",
    "                        ['phi_rad', 'loc_dev_ddm', 'crosswind_mps', 'hralt_m'], \n",
    "                    ]\n",
    "\n",
    "print (\"Num. of possibilities: {}\".format(len(feature_possibs)))\n",
    "print_list(feature_possibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index\n",
    "check_feature = [\n",
    "            'hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', \n",
    "            'gamma_error_rad', 'tailwind_mps', 'g_err_d_rad', # 'crosswind_mps',\n",
    "            'flap_4_bool', 'flap_5_bool', 'flap_6_bool',\n",
    "    ]\n",
    "current_index = 0\n",
    "\n",
    "if False:\n",
    "    for i, feature_poss in enumerate (feature_possibs):\n",
    "        \n",
    "        if collections.Counter(feature_poss) == collections.Counter(check_feature):\n",
    "            current_index = i\n",
    "            print (\"index -> {}\".format(current_index))\n",
    "            print (\"features -> {}\".format(feature_poss))\n",
    "            break\n",
    "\n",
    "    elapsed_time = 137 # Hours since 1.00 AM 20th July 2022\n",
    "    total_days = len(feature_possibs)/(current_index/elapsed_time)/24\n",
    "    remaining_days = total_days - elapsed_time/24\n",
    "\n",
    "    print ()\n",
    "    print (\"total_days: \\t\\t{:.2f}\".format(total_days))\n",
    "    print (\"remaining_days: \\t{:.2f}\".format(remaining_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_possibs[bin_to_index(\"1011\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_features(model_id: str, itter_times:int, collected_list:list, filename: str = \"features_search.pkl\"):\n",
    "    \n",
    "    # # Model Definition\n",
    "    # tf.keras.backend.clear_session()\n",
    "    # if model_id != None:\n",
    "    #     if not model_id in MODEL_DEFINITIONS:\n",
    "    #         print (\"Err: invalid model id -> {}\".format(model_id))\n",
    "    #         exit (1)\n",
    "\n",
    "    #     G_PARAMS.MODEL_ID = model_id\n",
    "    #     G_PARAMS.ApplyModelDefinition(\n",
    "    #         mdef.MODEL_DEFINITIONS[G_PARAMS.MODEL_ID]\n",
    "    #     )\n",
    "\n",
    "    # # Import Data\n",
    "    # train_comb= ImportCombinedTrainingData()\n",
    "\n",
    "    # # Pre-process Data\n",
    "    # train_comb, norm_param = DF_Nomalize(train_comb)\n",
    "    # train_list, test_list, eval_list = GetFileList()\n",
    "\n",
    "    # # Create WindowGenerator\n",
    "    # windowG = CreateWindowGenerator(train_list, \n",
    "    #                 test_list, eval_list, norm_param)\n",
    "    # test_dat = windowG.test\n",
    "\n",
    "    for features in feature_possibs:\n",
    "        val_data = {}\n",
    "        val_data_avg = {}\n",
    "\n",
    "        feature_summary = {}\n",
    "\n",
    "        G_PARAMS.FEATURE_COLUMNS = features\n",
    "        for i in range (itter_times):\n",
    "            clear_output(wait=True)\n",
    "            print (\"i = {}, feature -> {}\".format(i, features))\n",
    "            model, history = anntrainer.run(\n",
    "                model_id,\n",
    "                save_model = False,\n",
    "                return_model = True\n",
    "            )\n",
    "\n",
    "            print ()\n",
    "\n",
    "            # _, test_mse, test_mae = model.evaluate(test_dat)\n",
    "            # val_data['val_test_mean_squared_error'] = val_data.get('val_test_mean_squared_error', [])\n",
    "            # val_data['val_test_mean_squared_error'].append(test_mse)\n",
    "\n",
    "            # val_data['val_test_mean_absolute_error'] = val_data.get('val_test_mean_absolute_error', [])\n",
    "            # val_data['val_test_mean_absolute_error'].append(test_mae)\n",
    "\n",
    "            for key in history.history.keys():\n",
    "                if not key.startswith('val'):\n",
    "                    continue\n",
    "                min_value = min (history.history[key])\n",
    "                min_epoch = history.history[key].index(min_value)\n",
    "                # print (\"Minimum of {:<26} ->  {} \\t on epoch ->  {}\".format(key, min_value, min_index)) \n",
    "\n",
    "                val_data[key] = val_data.get(key, [])\n",
    "                val_data[key].append(min_value)\n",
    "\n",
    "                # Min Index\n",
    "                val_data[key + '_epoch'] = val_data.get(key + '_epoch', [])\n",
    "                val_data[key + '_epoch'].append(min_epoch)\n",
    "                \n",
    "\n",
    "        for key in val_data.keys():\n",
    "            val_data_avg[key] = np.average (val_data[key])\n",
    "\n",
    "        feature_summary['features']     = features\n",
    "        feature_summary['performance']  = val_data_avg\n",
    "\n",
    "        collected_list.append(feature_summary)\n",
    "        \n",
    "        # Save collected list\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(collected_list, f)\n",
    "\n",
    "\n",
    "    # Save collected list\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(collected_list, f)\n",
    "    print (\"picke saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'simp_dense_ail'\n",
    "itter_times = 5\n",
    "collected_list = []\n",
    "\n",
    "if False:\n",
    "    with open(\"features_search.pkl\", 'rb') as f:\n",
    "        collected_list = pickle.load(f)    \n",
    "\n",
    "if False: \n",
    "    search_features(model_id, itter_times, collected_list, filename='features_performance.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'features': ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps'],\n",
       "  'performance': {'val_loss': 0.5203588008880615,\n",
       "   'val_loss_epoch': 1.4,\n",
       "   'val_mean_squared_error': 0.5203588008880615,\n",
       "   'val_mean_squared_error_epoch': 1.4,\n",
       "   'val_mean_absolute_error': 0.46365341544151306,\n",
       "   'val_mean_absolute_error_epoch': 2.6}},\n",
       " {'features': ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad'],\n",
       "  'performance': {'val_loss': 0.5085821628570557,\n",
       "   'val_loss_epoch': 2.0,\n",
       "   'val_mean_squared_error': 0.5085821628570557,\n",
       "   'val_mean_squared_error_epoch': 2.0,\n",
       "   'val_mean_absolute_error': 0.45907732248306277,\n",
       "   'val_mean_absolute_error_epoch': 1.8}},\n",
       " {'features': ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad'],\n",
       "  'performance': {'val_loss': 0.5053481698036194,\n",
       "   'val_loss_epoch': 2.8,\n",
       "   'val_mean_squared_error': 0.5053481698036194,\n",
       "   'val_mean_squared_error_epoch': 2.8,\n",
       "   'val_mean_absolute_error': 0.4580515265464783,\n",
       "   'val_mean_absolute_error_epoch': 3.2}},\n",
       " {'features': ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'g_err_i_rad'],\n",
       "  'performance': {'val_loss': 0.5106477379798889,\n",
       "   'val_loss_epoch': 2.0,\n",
       "   'val_mean_squared_error': 0.5106477379798889,\n",
       "   'val_mean_squared_error_epoch': 2.0,\n",
       "   'val_mean_absolute_error': 0.461227947473526,\n",
       "   'val_mean_absolute_error_epoch': 3.4}},\n",
       " {'features': ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'g_err_i_rad',\n",
       "   'tailwind_mps'],\n",
       "  'performance': {'val_loss': 0.49020100235939024,\n",
       "   'val_loss_epoch': 3.2,\n",
       "   'val_mean_squared_error': 0.49020100235939024,\n",
       "   'val_mean_squared_error_epoch': 3.2,\n",
       "   'val_mean_absolute_error': 0.4360851228237152,\n",
       "   'val_mean_absolute_error_epoch': 4.4}},\n",
       " {'features': ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'tailwind_mps'],\n",
       "  'performance': {'val_loss': 0.48692888021469116,\n",
       "   'val_loss_epoch': 3.4,\n",
       "   'val_mean_squared_error': 0.48692888021469116,\n",
       "   'val_mean_squared_error_epoch': 3.4,\n",
       "   'val_mean_absolute_error': 0.43384069204330444,\n",
       "   'val_mean_absolute_error_epoch': 3.8}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"features_performance.pkl\", 'rb') as f:\n",
    "    loaded_result = pickle.load(f)\n",
    "\n",
    "loaded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': [['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps'],\n",
       "  ['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad'],\n",
       "  ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad'],\n",
       "  ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'g_err_i_rad'],\n",
       "  ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'g_err_i_rad',\n",
       "   'tailwind_mps'],\n",
       "  ['hralt_m',\n",
       "   'hdot_1_mps',\n",
       "   'theta_rad',\n",
       "   'cas_mps',\n",
       "   'gamma_error_rad',\n",
       "   'g_err_d_rad',\n",
       "   'tailwind_mps']],\n",
       " 'val_mean_squared_error': [0.5203588008880615,\n",
       "  0.5085821628570557,\n",
       "  0.5053481698036194,\n",
       "  0.5106477379798889,\n",
       "  0.49020100235939024,\n",
       "  0.48692888021469116],\n",
       " 'val_mean_absolute_error': [0.46365341544151306,\n",
       "  0.45907732248306277,\n",
       "  0.4580515265464783,\n",
       "  0.461227947473526,\n",
       "  0.4360851228237152,\n",
       "  0.43384069204330444]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dict = {}\n",
    "params = ['val_mean_squared_error', 'val_mean_absolute_error']\n",
    "\n",
    "for i, result in enumerate(loaded_result):\n",
    "    new_dict['features'] = new_dict.get('features', [])\n",
    "    new_dict['features'].append(result['features'])\n",
    "\n",
    "    for param in params:\n",
    "        new_dict[param] = new_dict.get(param, [])\n",
    "        new_dict[param].append(result['performance'][param])\n",
    "\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad', 'tailwind_mps']\n",
      "['hralt_m', 'hdot_1_mps', 'theta_rad', 'cas_mps', 'gamma_error_rad', 'g_err_d_rad', 'tailwind_mps']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps]</td>\n",
       "      <td>0.520359</td>\n",
       "      <td>0.463653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.508582</td>\n",
       "      <td>0.459077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.505348</td>\n",
       "      <td>0.458052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.510648</td>\n",
       "      <td>0.461228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.490201</td>\n",
       "      <td>0.436085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.486929</td>\n",
       "      <td>0.433841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  val_mean_squared_error  \\\n",
       "0          [hralt_m, hdot_1_mps, theta_rad, cas_mps]                0.520359   \n",
       "1  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.508582   \n",
       "2  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.505348   \n",
       "3  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.510648   \n",
       "4  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.490201   \n",
       "5  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.486929   \n",
       "\n",
       "   val_mean_absolute_error  \n",
       "0                 0.463653  \n",
       "1                 0.459077  \n",
       "2                 0.458052  \n",
       "3                 0.461228  \n",
       "4                 0.436085  \n",
       "5                 0.433841  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame(new_dict)\n",
    "\n",
    "\n",
    "for feat in new_dict['features']:\n",
    "    print (feat)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...</td>\n",
       "      <td>0.486929</td>\n",
       "      <td>0.433841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  val_mean_squared_error  \\\n",
       "5  [hralt_m, hdot_1_mps, theta_rad, cas_mps, gamm...                0.486929   \n",
       "\n",
       "   val_mean_absolute_error  \n",
       "5                 0.433841  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[new_df['val_mean_absolute_error'] == new_df['val_mean_absolute_error'].min()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns = ['Features', 'MSE', 'MAE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16053/2666013993.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  new_df.to_latex(\n"
     ]
    }
   ],
   "source": [
    "new_df.to_latex(\n",
    "        'ch3_feature_eng_20.tex',\n",
    "        index=False,\n",
    "        caption=\"Pengaruh Features Terhadap Perfroma Model (MSE dan MAE)\", \n",
    "        label='tab:ch3_feature_eng'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print (\"Loaded from pkl: {}\".format(len (loaded_result)))\n",
    "\n",
    "    sorted_features = sorted(loaded_result, key=lambda x: x['performance']['val_mean_absolute_error'])\n",
    "    best_10s = sorted_features[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_counts = {}\n",
    "\n",
    "# for data in best_10s:\n",
    "#     for feature in data['features']:\n",
    "#         feat_counts[feature] = feat_counts.get(feature, 0) + 1\n",
    "\n",
    "# feat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_10s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_result [1780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4680a687c0b493607a5a84d99aa6299372553ac8fbb569a372de15fbb66a08e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
