{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# TENSORFLOW LOGS:\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.api import keras\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from hpcscripts.sharedutils.trainingutils import LoadModel, SetLowTFVerbose, MakeSinglePrediction, CreateWindowGenerator, GetFileList, TrainModel\n",
    "from hpcscripts.sharedutils.nomalization import DF_Nomalize, denorm\n",
    "from hpcscripts.sharedutils.modelutils import SelectModelPrompt\n",
    "from hpcscripts.trainers.anntrainer import CreateANNModel, ImportCombinedTrainingData\n",
    "from hpcscripts.trainers.modeldefinitions import  MODEL_DEFINITIONS\n",
    "from hpcscripts.trainers import modeldefinitions as mdef\n",
    "from hpcscripts.trainers import anntrainer\n",
    "from hpcscripts.option import pathhandler as ph\n",
    "from hpcscripts.option import globalparams as G_PARAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Functions Defninition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary(digits_num: int, init_val: int=0):\n",
    "    return [init_val for i in range (digits_num)]\n",
    "\n",
    "def increment_binary(binary: list):\n",
    "    hold = 0\n",
    "    for i in range (len(binary)):\n",
    "        index = len(binary) - i - 1\n",
    "        \n",
    "        if index == 0 and binary[index] == 1 and hold > 0:\n",
    "            return -1\n",
    "        if i == 0:\n",
    "            binary [index] += 1\n",
    "\n",
    "        binary [index] += hold\n",
    "        hold = 0\n",
    "\n",
    "        if binary[index] > 1:\n",
    "            binary[index] = 0\n",
    "            hold = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def create_possibility_mask(digits_num: int):\n",
    "    possibilities = []\n",
    "    binary = create_binary(digits_num)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        binary = increment_binary(binary)\n",
    "\n",
    "        if binary == -1:\n",
    "            break\n",
    "\n",
    "        possibilities.append(binary.copy())\n",
    "\n",
    "    return possibilities\n",
    "\n",
    "def create_possible_features(feature_list: list):\n",
    "    digits_num = len (feature_list)\n",
    "    possi_mask = create_possibility_mask(digits_num)\n",
    "\n",
    "    feature_possibs = []\n",
    "    for possi in possi_mask:\n",
    "        new_features = []\n",
    "        for mask, feature in zip(possi, feature_list):\n",
    "            if mask == 1:\n",
    "                new_features.append(feature)\n",
    "\n",
    "        feature_possibs.append(new_features)\n",
    "    \n",
    "    return feature_possibs, possi_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(the_list: list):\n",
    "    for element in the_list:\n",
    "        print (element)\n",
    "        \n",
    "def bin_to_index(binary: str = \"1010\"):\n",
    "    index = -1\n",
    "    for n, letter in enumerate(binary[::-1]):\n",
    "        if letter == \"1\":\n",
    "            index += 2**n\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Create Possible Labels Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "                'hralt_m', 'theta_rad', 'aoac_rad', 'cas_mps', 'hdot_1_mps',\n",
    "                'gamma_error_rad', 'g_err_d_rad', 'g_err_i_rad',\n",
    "                'tailwind_mps', 'crosswind_mps',\n",
    "                'use_flap'\n",
    "                ]\n",
    "                # 'flap_4_bool', 'flap_5_bool', 'flap_6_bool'\n",
    "# label_list = [\"hralt_m\", \"theta_rad\", \"aoac_rad\", \"cas_mps\"]\n",
    "# feature_list = [\"hralt_m\", \"theta_rad\"]\n",
    "\n",
    "feature_possibs, possi_mask = create_possible_features(feature_list)\n",
    "\n",
    "for i, feature_poss in enumerate (feature_possibs):\n",
    "    if 'use_flap' in feature_poss:\n",
    "        feature_poss.remove('use_flap')\n",
    "        feature_poss = feature_poss + ['flap_4_bool', 'flap_5_bool', 'flap_6_bool']\n",
    "\n",
    "        feature_possibs[i] = feature_poss\n",
    "\n",
    "print (\"Num. of possibilities: {}\".format(len(feature_possibs)))\n",
    "print_list(feature_possibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_possibs[bin_to_index(\"1011\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_features(model_id: str, itter_times:int, collected_list:list):\n",
    "    for features in feature_possibs:\n",
    "        val_data = {}\n",
    "        val_data_avg = {}\n",
    "\n",
    "        feature_summary = {}\n",
    "\n",
    "        G_PARAMS.FEATURE_COLUMNS = features\n",
    "        for i in range (itter_times):\n",
    "            clear_output(wait=True)\n",
    "            print (\"i = {}, feature -> {}\".format(i, features))\n",
    "            model, history = anntrainer.run(\n",
    "                model_id,\n",
    "                save_model = False,\n",
    "                return_model = True\n",
    "            )\n",
    "\n",
    "            print ()\n",
    "\n",
    "            for key in history.history.keys():\n",
    "                if not key.startswith('val'):\n",
    "                    continue\n",
    "                min_value = min (history.history[key])\n",
    "                min_epoch = history.history[key].index(min_value)\n",
    "                # print (\"Minimum of {:<26} ->  {} \\t on epoch ->  {}\".format(key, min_value, min_index)) \n",
    "\n",
    "                val_data[key] = val_data.get(key, [])\n",
    "                val_data[key].append(min_value)\n",
    "\n",
    "                # Min Index\n",
    "                val_data[key + '_epoch'] = val_data.get(key + '_epoch', [])\n",
    "                val_data[key + '_epoch'].append(min_epoch)\n",
    "                \n",
    "\n",
    "        for key in val_data.keys():\n",
    "            val_data_avg[key] = np.average (val_data[key])\n",
    "\n",
    "        feature_summary['features']     = features\n",
    "        feature_summary['performance']  = val_data_avg\n",
    "\n",
    "        collected_list.append(feature_summary)\n",
    "        \n",
    "        # Save collected list\n",
    "        with open(\"features_search.pkl\", 'wb') as f:\n",
    "            pickle.dump(collected_list, f)\n",
    "\n",
    "\n",
    "    # Save collected list\n",
    "    with open(\"features_search.pkl\", 'wb') as f:\n",
    "        pickle.dump(collected_list, f)\n",
    "    print (\"picke saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'simp_dense'\n",
    "itter_times = 5\n",
    "collected_list = []\n",
    "\n",
    "if False:\n",
    "    with open(\"features_search.pkl\", 'rb') as f:\n",
    "        collected_list = pickle.load(f)    \n",
    "\n",
    "if True: \n",
    "    search_features(model_id, itter_times, collected_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_search.pkl\", 'rb') as f:\n",
    "    loaded_result = pickle.load(f)\n",
    "\n",
    "loaded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print (\"Loaded from pkl: {}\".format(len (loaded_result)))\n",
    "\n",
    "    sorted_features = sorted(loaded_result, key=lambda x: x['performance']['val_mean_absolute_error'])\n",
    "    best_10s = sorted_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_counts = {}\n",
    "\n",
    "# for data in best_10s:\n",
    "#     for feature in data['features']:\n",
    "#         feat_counts[feature] = feat_counts.get(feature, 0) + 1\n",
    "\n",
    "# feat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4680a687c0b493607a5a84d99aa6299372553ac8fbb569a372de15fbb66a08e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
